{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from models.GNN_models import Model_GCN, Model_GAT, APPNP, DAGNN\n",
    "from utils.preprocess import norm_adj, norm_hop_adj, data_split, clean_A, remove_edge_pts\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "import dgl.data\n",
    "import dgl\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_f1(model, x, y, val_mask, test_mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(x)\n",
    "        y_pred_val = y_pred[val_mask]\n",
    "        y_pred_test = y_pred[test_mask]\n",
    "        pred_val = y_pred_val.argmax(1)\n",
    "        pred_test = y_pred_test.argmax(1)\n",
    "        val_f1 = metrics.f1_score(y[val_mask].cpu().numpy(), pred_val.cpu().numpy(), average='macro')\n",
    "        test_f1 = metrics.f1_score(y[test_mask].cpu().numpy(), pred_test.cpu().numpy(), average='macro')\n",
    "        return val_f1, test_f1\n",
    "    \n",
    "def evaluate_acc(model, x, y, val_mask, test_mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(x)\n",
    "        y_pred_val = y_pred[val_mask]\n",
    "        y_pred_test = y_pred[test_mask]\n",
    "        pred_val = y_pred_val.argmax(1)\n",
    "        pred_test = y_pred_test.argmax(1)\n",
    "        val_acc = (y[val_mask] == pred_val).float().mean().item()\n",
    "        test_acc = (y[test_mask] == pred_test).float().mean().item()\n",
    "        return val_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x, y, train_mask, val_mask, test_mask, args):\n",
    "    device = args.device\n",
    "    model.to(device)\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "    count = 0\n",
    "    \n",
    "    tic = time.time()\n",
    "    for epoch in range(args.num_iter):    \n",
    "        model.train()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred[train_mask], y[train_mask])\n",
    "        val_acc, test_acc = evaluate_acc(model, x, y, val_mask, test_mask)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            count = 0\n",
    "        elif count >= args.patience:\n",
    "            break\n",
    "        else:\n",
    "            count += 1\n",
    "    print('time duration = {:.3f}, best_val_acc = {:.3f}, best_test_acc = {:.3f}'.\n",
    "          format(time.time() - tic, best_val_acc, best_test_acc))\n",
    "    #model = model.to('cpu')\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    return best_test_acc, model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acc(x, y, A, train_mask, val_mask, test_mask, args):\n",
    "    accs = []\n",
    "    for _ in range(args.num_test):\n",
    "        if args.model == 'GCN':\n",
    "            n_dims = [args.n_in] + [args.n_hid] * args.hop + [args.n_out]\n",
    "            #print('n_dims: ', n_dims)\n",
    "            model = Model_GCN(n_dims, A, args.dropout)\n",
    "        elif args.model == 'GAT':\n",
    "            n_dims = [args.n_in] + [args.n_hid] * args.hop + [args.n_out]\n",
    "            #print('n_dims: ', n_dims)\n",
    "            n_heads = [args.num_heads] * args.hop + [args.num_out_heads]\n",
    "            #print('n_heads: ', n_heads)\n",
    "            model = Model_GAT(n_dims, n_heads, A, args.dropout, args.dropout2)\n",
    "        elif args.model == 'APPNP':\n",
    "            model = APPNP(args.n_in, args.n_hid, args.n_out, A, args.dropout, args.dropout2, args.hop, args.alpha)\n",
    "        elif args.model == 'DAGNN':\n",
    "            model = DAGNN(args.n_in, args.n_hid, args.n_out, A, args.hop, args.dropout)\n",
    "        acc, _ = train(model, x, y, train_mask, val_mask, test_mask, args)\n",
    "        accs.append(acc) \n",
    "    accs = np.array(accs)\n",
    "    print('test acc = ', accs.mean())\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    if args.data == 'Citeseer':\n",
    "        dataset = dgl.data.CiteseerGraphDataset()\n",
    "    elif args.data == 'Pubmed':\n",
    "        dataset = dgl.data.PubmedGraphDataset()\n",
    "    elif args.data == 'Coauthor-CS':\n",
    "        dataset = dgl.data.CoauthorCSDataset()\n",
    "    else:\n",
    "        dataset = dgl.data.CoraGraphDataset()\n",
    "    g = dataset[0]\n",
    "    A = g.adjacency_matrix()\n",
    "    A = clean_A(A)\n",
    "    x = g.ndata['feat']\n",
    "    y = g.ndata['label']\n",
    "\n",
    "    args.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    args.n_in, args.n_out = x.size(1), len(set(y.tolist()))\n",
    "    if args.data == 'Coauthor-CS' or args.random_label_split:\n",
    "        if args.data_load:\n",
    "            train_mask = torch.load('./label_split/train_mask_' + args.data + str(args.test_id) + '.pt')\n",
    "            val_mask = torch.load('./label_split/val_mask_' + args.data + str(args.test_id) + '.pt')\n",
    "            test_mask = torch.load('./label_split/test_mask_' + args.data + str(args.test_id) + '.pt')\n",
    "        else:\n",
    "            # generate label split randomly\n",
    "            train_mask, val_mask, test_mask = data_split(x, y, training_samples=args.num_train, val_samples=args.num_val)\n",
    "            torch.save(train_mask, './label_split/train_mask_' + args.data + str(args.test_id) + '.pt')\n",
    "            torch.save(val_mask, './label_split/val_mask_' + args.data + str(args.test_id) + '.pt')\n",
    "            torch.save(test_mask, './label_split/test_mask_' + args.data + str(args.test_id) + '.pt')\n",
    "    else:\n",
    "        train_mask = g.ndata['train_mask']\n",
    "        val_mask = g.ndata['val_mask']\n",
    "        test_mask = g.ndata['test_mask']\n",
    "    accs = test_acc(x, y, A, train_mask, val_mask, test_mask, args)\n",
    "    print('test accuracy (mean, std): ', accs.mean(), accs.std())\n",
    "    acc = remove_edge_pts(accs, pct=args.filter_pct)\n",
    "    print('test accuracy (mean, std) after filter: ', acc.mean(), acc.std())\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5, 0.5, 0.005, 5e-4 for AmazonCoBuy 0.8, 0.5 ,0.01, 5e-4 for Pubmed, 0.8, 0.6, 0.01, 5e-4 for citeseer\n",
    "class config:\n",
    "    data = 'Cora'\n",
    "    model = 'APPNP'\n",
    "    n_in = 0\n",
    "    n_hid = 8\n",
    "    n_out = 0\n",
    "    num_heads = 8\n",
    "    num_out_heads = 1\n",
    "    device = 'cpu'\n",
    "    dropout = 0.6\n",
    "    dropout2 = 0.6\n",
    "    #GCN_dropout = 0.5\n",
    "    #GAT_dropout = 0.6\n",
    "    #GAT_attn_dropout = 0.6\n",
    "    #APPNP_dropout1 = 0.5\n",
    "    #APPNP_dropout2 = 0.5\n",
    "    #DAGNN_dropout = 0.8\n",
    "    #GTreeConv_dropout1 = 0.6\n",
    "    #GTreeConv_dropout2 = 0.6\n",
    "    learning_rate = 0.005\n",
    "    weight_decay = 1e-3\n",
    "    patience = 100\n",
    "    num_iter = 1000\n",
    "    num_test = 30\n",
    "    hop = 1\n",
    "    alpha = 0.1 # used by APPNP only\n",
    "    random_label_split = False\n",
    "    num_train = 20 # for random label split only\n",
    "    num_val = 30 # for random label split only\n",
    "    data_load = False # load the saved label split to rerun the test (for reproduce purpose)\n",
    "    test_id = 1 # number of the test, only used to record the ith number of the random label split (for reproduce purpose)\n",
    "    filter_pct = 0.1 # remove the top and bottom filer_pct points before obtaining statistics of test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "self_loop # =  0\n",
      "time duration = 14.869, best_val_acc = 0.762, best_test_acc = 0.768\n",
      "time duration = 26.690, best_val_acc = 0.772, best_test_acc = 0.779\n",
      "time duration = 22.758, best_val_acc = 0.800, best_test_acc = 0.789\n",
      "time duration = 17.741, best_val_acc = 0.780, best_test_acc = 0.795\n",
      "time duration = 17.243, best_val_acc = 0.736, best_test_acc = 0.750\n",
      "time duration = 28.284, best_val_acc = 0.788, best_test_acc = 0.768\n",
      "time duration = 23.038, best_val_acc = 0.774, best_test_acc = 0.786\n",
      "time duration = 22.121, best_val_acc = 0.772, best_test_acc = 0.788\n",
      "time duration = 14.324, best_val_acc = 0.784, best_test_acc = 0.798\n",
      "time duration = 13.821, best_val_acc = 0.774, best_test_acc = 0.790\n",
      "time duration = 24.179, best_val_acc = 0.786, best_test_acc = 0.796\n",
      "time duration = 25.181, best_val_acc = 0.792, best_test_acc = 0.802\n",
      "time duration = 19.509, best_val_acc = 0.776, best_test_acc = 0.775\n",
      "time duration = 23.556, best_val_acc = 0.766, best_test_acc = 0.787\n",
      "time duration = 15.291, best_val_acc = 0.756, best_test_acc = 0.772\n",
      "time duration = 21.036, best_val_acc = 0.768, best_test_acc = 0.765\n",
      "time duration = 21.887, best_val_acc = 0.792, best_test_acc = 0.790\n",
      "time duration = 17.479, best_val_acc = 0.788, best_test_acc = 0.780\n",
      "time duration = 14.266, best_val_acc = 0.770, best_test_acc = 0.766\n",
      "time duration = 19.019, best_val_acc = 0.754, best_test_acc = 0.778\n",
      "time duration = 20.000, best_val_acc = 0.792, best_test_acc = 0.785\n",
      "time duration = 12.737, best_val_acc = 0.764, best_test_acc = 0.766\n",
      "time duration = 16.109, best_val_acc = 0.774, best_test_acc = 0.785\n",
      "time duration = 21.758, best_val_acc = 0.796, best_test_acc = 0.805\n",
      "time duration = 24.739, best_val_acc = 0.776, best_test_acc = 0.776\n",
      "time duration = 23.786, best_val_acc = 0.778, best_test_acc = 0.788\n",
      "time duration = 21.996, best_val_acc = 0.784, best_test_acc = 0.785\n",
      "time duration = 20.322, best_val_acc = 0.768, best_test_acc = 0.780\n",
      "time duration = 25.587, best_val_acc = 0.792, best_test_acc = 0.806\n",
      "time duration = 25.342, best_val_acc = 0.780, best_test_acc = 0.784\n",
      "test acc =  0.7827333311239878\n",
      "test accuracy (mean, std):  0.7827333311239878 0.012735604425615036\n",
      "test accuracy (mean, std) after filter:  0.7828333328167597 0.008639382538064852\n"
     ]
    }
   ],
   "source": [
    "args = config()\n",
    "accs = main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
